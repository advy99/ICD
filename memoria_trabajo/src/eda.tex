\section{Análisis exploratorio de datos}

En este primer apartado realizaremos el análisis de los datos. Este análisis inicial nos servirá para visualizar como son los datos, si existen relaciones entre las distintas características que los conforman, así como extraer información de cada característica como pueden ser sus valores de interés, si cuenta con valores perdidos o anomalías así como más información. Además, también nos servirá para realizar hipótesis sobre como se comportarán los distintos predictores a la hora de generar un modelo, si algunos modelos no funcionarán debido a como están distribuidos los datos, entre otras.

\subsection{Conjunto de datos para regresión: baseball}

\subsubsection{Descripción del conjunto de datos}

Este conjunto de datos contiene información sobre distintas estadísticas de jugadores de béisbol, como el número de veces que batean, el número de partidos que juegan, los errores, entre otras estadísticas, así como su salario, que será el valor de salida que intentamos predecir.

Tras esta descripción del conjunto de datos, vamos a pasar a obtener distintas medidas de interés sobre los datos.


\subsubsection{Medidas de interés}

Lo primero a consultar de nuestro conjunto de datos es las dimensiones del mismo. Tras hacer uso del comando \texttt{dim}, vemos que el conjunto cuenta con 337 filas y 17 características (contando con la variable objetivo).

Tras esto pasamos a consultar el tipo de las características de cara a comprobar que se han leído de forma correcta. El comando \texttt{str} nos devolverá esta información, y vemos como todas son de tipo entero, a excepción del porcentaje de bateo y el porcentaje que un jugador llega a una base, que son de tipo numérico al contar con decimales.

Lo siguiente que comprobaremos, antes de consultar los propios valores de las variables será comprobar si existen valores perdidos. Para esto utilizaremos el comando \texttt{is.na} junto con el comando \texttt{any} para saber si se encuentra algún valor perdido. De forma gráfica también podemos utilizar el gráfico \texttt{missmap} del paquete Amelia:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/missmap_baseball}
	\caption{Mapa de valores perdidos en el conjunto de datos baseball.}
	\label{fig:missmap_baseball}
\end{figure}

Como vemos, este conjunto de datos no cuenta con valores perdidos, por lo que con esto pasamos a calcular las medidas de interés de cada predictor.


De cara a conocer el comportamiento de las características se han calculado los siguientes valores de interés para cada predictor:

\begin{itemize}
	\item Media
	\item Desviación estándar
	\item Mínimo
	\item Máximo
	\item Cuartiles
\end{itemize}


Estos valores los podemos consultar en el código en R adjunto, y aquí me comentaré la información más interesante que se ha obtenido.

Para empezar, observando los mínimos, máximos y cuartiles de las característica podemos ver que cuatro de los predictores, Free agency eligibility, Free agent, Arbitration eligibility y Arbitration, se han leído como valores numéricos del fichero de datos aunque se tratan de variables lógicas que solo toman dos valores, cero o uno.

Otro dato de interés con respecto a la variable de salida es que la media y la mediana son muy distintas, siendo la mediana casi la mitad del salario medio, sumado al gran valor de la desviación estándar del salario, podemos intuir que la mayoría de jugadores cobran un salario mucho menor que el salario máximo.

\subsubsection{Visualización gráfica del conjunto de datos}

Tras este primer vistazo a los datos y sus valores de interés, pasamos a representarlos de forma gráfica los datos.

Para empezar se ha realizado una gráfica general de los datos utilizando el comando \texttt{ggpairs}:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{baseball/vista_general_baseball}
	\caption{Vista general del conjunto de datos baseball.}
	\label{fig:vista_general_baseball}
\end{figure}

Aunque esta gráfica es muy difícil de leer ya que tenemos una gran cantidad de características, nos da una primera idea de que relaciones existen entre las variables así como su distribución.

Para ver más en detalle los valores que toma cada variable vamos ver un boxplot de cada una:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{baseball/boxplot_baseball}
	\caption{Boxplot de cada variable de baseball. \textbf{AVISO}: Mirar cada gráfica de forma independiente, la escala está libre.}
	\label{fig:boxplot_baseball}
\end{figure}

Se ha decidido poner la escala libre para evitar que una variable con valores muy amplios no nos deje ver los valores de las demás, por lo que hay que estudiar cada gráfica por separado y no realizar comparativas de estos gráficos sin tener en cuenta los ejes individuales de cada gráfica.

Con este gráfico podemos obtener bastante información sobre las variables. Para empezar, podemos observar que muchas de estas tienen valores anómalos según el método IQR, que aunque en principio en esta asignatura no trabajemos anomalías es algo que tenemos que tener en cuenta al usar estos predictores en nuestros modelos. También podemos ver que en ciertas variables como Batting average y On base percentage la mayoría de valores se concentran en un rango muy pequeño de valores, teniendo la mitad de valores entre el $0.24$ y el $0.3$ y entre $0.3$ y $0.36$ respectivamente, siendo ambas variables que expresan un porcentaje entre cero y uno. Otra variable a la que le ocurre lo mismo es a Stolen bases, donde la mitad de sus datos están entre el 0 y el 16, contando con bastantes valores anómalos.

Otra información a destacar de este gráfico son los cuatro boxplot de la esquina superior izquierda, Arbitration, Arbitration eligibility, Free agent eligibility y Free agent, que como vemos solo toman valores cero y uno, de ahí esas formas tan peculiares en los boxplots.


También se ha observado el gráfico de densidad de las características, de cara a observar la forma de la distribución en los datos:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/densidad_baseball}
	\caption{Gráfico de densidad de cada variable de baseball. \textbf{AVISO}: Mirar cada gráfica de forma independiente, la escala está libre.}
	\label{fig:densidad_baseball}
\end{figure}

Rápidamente podemos ver que tenemos una gran variedad de distribuciones. Como era de esperar, en las variables lógicas encontramos una distribución bimodal, aunque con este gráfico podemos ver que, a excepción de Free agency eligibility, en las otras tres variables predomina el valor cero.

Visualmente podemos ver que la que más se acerca a una distribución normal es Batting average, aunque tiene algunos valores en la cola izquierda que nos pueden hacer dudar si finalmente seguirá una normal.

Para ver esto más claramente, utilizaremos los gráficos Q-Q:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/qqplot_todos_baseball}
	\caption{Gráfico de normalidad Q-Q de cada variable de baseball.}
	\label{fig:qqplot_todos_baseball}
\end{figure}

En este gráfico podemos ver como, de nuevo, la más parecida a una normal es Batting average, aunque vemos como en las colas (en especial en la izquierda) observamos datos que no están sobre la linea.

De cara a comprobar estadisticamente si alguna de estas distribuciones es una distribución normal se ha aplicado el test de normalidad de Shapiro-Wilk, con el que no se ha podido rechazar la hipótesis nula para ninguna de las variables, luego no podemos concluir que sigan una distribución normal.

Finalmente, de cara a observar las relaciones entre las variables y si existe alguna correlación con la de salida se ha realizado un gráfico de la matriz de correlación:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/matriz_correlaciones_baseball}
	\caption{Matriz de correlaciones entre las variables de baseball.}
	\label{fig:matriz_correlaciones_baseball}
\end{figure}

De este gráfico podemos observar que existe un grupo de predictores altamente relacionados entre sí, Runs, Hits, Doubles y Runs batted in, por lo que se podría estudiar eliminar alguno de estos predictores para obtener un modelo más simple. También podemos observar que este grupo de predictores tiene una relación relativamente alta con la variable a predecir.

También existen otras variables que están correladas, como Batting average y On base percentaje, ya que tiene sentido que si un jugador batea más, tenga más probabilidad de llegar a una base, o entre On base percentage y Walks por el mismo motivo.


\subsection{Conjunto de datos para clasificación: iris}

\subsubsection{Descripción del conjunto de datos}

Este conjunto contiene información sobre las medidas del pétalo y sépalo de tres tipos distintos de la flor Iris. Nos proporciona tanto la longitud como el ancho del pétalo y sépalo de estas tres clases:

\begin{itemize}
	\item Versicolor
	\item Virginica
	\item Setosa
\end{itemize}

\subsubsection{Medidas de interés}

Lo primero a consultar de nuestro conjunto de datos es las dimensiones del mismo. Tras hacer uso del comando \texttt{dim}, vemos que el conjunto cuenta con 150 filas y 5 características (contando con la clase a predecir).

Tras esto pasamos a consultar el tipo de las características de cara a comprobar que se han leído de forma correcta. El comando \texttt{str} nos devolverá esta información, y vemos como todas a excepción de la clase son de tipo numérico al contar con decimales. La clase a la que pertenecen le ha asignado el tipo carácter, sin embargo lo vamos a transformar a factor con el comando \texttt{as.factor} ya que se tratan de tres niveles sin orden distintos, las tres clases a clasificar.

Al igual que con el conjunto de regresión, antes de consultar los propios valores de las variables será comprobar si existen valores perdidos. Para esto utilizaremos el comando \texttt{is.na} junto con el comando \texttt{any} para saber si se encuentra algún valor perdido. De forma gráfica también podemos utilizar el gráfico \texttt{missmap} del paquete Amelia:


\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{iris/missmap_iris}
	\caption{Mapa de valores perdidos en el conjunto de datos iris.}
	\label{fig:missmap_iris}
\end{figure}

Como podemos ver, en este conjunto de datos tampoco existen valores perdidos.

Como en regresión, se han calculado los siguientes valores de interés para cada predictor (a excepción de la clase ya que no es de tipo numérico):

\begin{itemize}
	\item Media
	\item Desviación estándar
	\item Mínimo
	\item Máximo
	\item Cuartiles
\end{itemize}


Estos valores los podemos consultar en el código en R adjunto, y aquí me comentaré la información más interesante que se ha obtenido.

Como podemos ver con los máximos y mínimos, todos los valores están en un rango similar de valores. Con estos valores vemos que son relativamente normales, en los que se asemeja la media con la mediana, aunque es cierto que podemos ver que para la variable PetalLength la desviación típica es más alta que para las demás.

\subsubsection{Visualización gráfica del conjunto de datos}

Para comenzar, también realizaremos una gráfica más general para ver de una manera más rápida el conjunto de datos iris:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/vista_general_iris}
	\caption{Vista general del conjunto de datos iris.}
	\label{fig:vista_general_iris}
\end{figure}


Con este gráfico podemos comenzar a obtener información bastante interesante, aun así voy a utilizar los gráficos completos para mostrar una mejor visualización, comenzando por el número de observaciones para cada clase, ya que esto es muy importante en un problema de clasificación:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{iris/recuento_clases_iris}
	\caption{Número de observaciones de cada clase para el conjunto de datos iris.}
	\label{fig:recuento_clases_iris}
\end{figure}

Como vemos, en este caso las clases están balanceadas, es decir, tenemos el mismo número de observaciones para cada clase, lo que ayudará a evitar que se sobreaprendan algunas clases, o que no tengamos suficientes muestras como para aprender una clase.

En esta sección, debido que el problema se basa en ser capaces de distinguir entre las clases en los gráficos distinguiremos las clases del problema. Vamos a empezar con los boxplot para ver como están distribuidos los valores de cada predictor:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_SepalWidth}
	\caption{Boxplot para el predictor SepalWidth de iris.}
	\label{fig:boxplot_iris_SepalWidth}
\end{figure}


\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_SepalLength}
	\caption{Boxplot para el predictor SepalLength de iris.}
	\label{fig:densidad_iris_SepalLength}
\end{figure}


\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_PetalWidth}
	\caption{Boxplot para el predictor PetalWidth de iris.}
	\label{fig:boxplot_iris_PetalWidth}
\end{figure}


\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_PetalLength}
	\caption{Boxplot para el predictor PetalLength de iris.}
	\label{fig:boxplot_iris_PetalLength}
\end{figure}


Y con esto pasamos a los gráficos de densidad:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_SepalWidth}
	\caption{Gráfico de densidad para el predictor SepalWidth de iris.}
	\label{fig:densidad_iris_SepalWidth}
\end{figure}

Con este primer gráfico de densidad, del predictor SepalWidth, podemos ver que este predictor no será capaz de realizar una buena distinción entre las clases, ya que se solapan todas en gran medida, aunque es cierto que se pueden observar ciertas diferencias con la clase Setosa.

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_SepalLength}
	\caption{Gráfico de densidad para el predictor SepalLength de iris.}
	\label{fig:densidad_iris_SepalLength}
\end{figure}

La variable SepalWidth es capaz de distinguir de mejor forma las clases, en especial Setosa, aunque sigue existiendo un gran solape entre Versicolor y Virginica.

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_PetalWidth}
	\caption{Gráfico de densidad para el predictor PetalWidth de iris.}
	\label{fig:densidad_iris_PetalWidth}
\end{figure}

En este caso podemos ver como con PetalWidth podemos hacer una distinción perfecta entre Setosa y el resto de clases, además de reducir en gran cantidad el solape entre Versicolor y Virginica.

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_PetalLength}
	\caption{Gráfico de densidad para el predictor PetalLength de iris.}
	\label{fig:densidad_iris_PetalLength}
\end{figure}

Por último, con PetalLength también se puede hacer una distinción perfecta entre Setosa y el resto de clases, aunque sigue existiendo un solape entre Versicolor y Virginica.

Con estos cuatro gráficos vemos que podemos esperar distinguir las observaciones de Setosa con el resto sin ningún problema gracias a las medidas del pétalo, haciendo que los errores se encuentren en las clases Versicolor y Virginica, aunque este error no será muy alto ya que también gracias a las medidas del pétalo el solape es menor, y posiblemente con toda la información en conjunto se consiga distinguir todavía mejor ese solape que vemos ahora.


Tras estos gráficos de densidad, pasamos a observar si los predictores siguen una distribución normal, para esto se ha usado de nuevo el gráfico Q-Q, además del test estadístico de Shapiro-Wilk:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/qqplot_iris}
	\caption{Gráfico de normalidad Q-Q de cada variable de iris.}
	\label{fig:qqplot_iris}
\end{figure}


Podemos ver que gráficamente la que más se acerca a una distribución normal es SepalWidth, aunque los valores en la cola derecha nos dan a intuir que no será así.

Tras lanzar el test de normalidad de Shapiro-Wilk rechazamos la hipótesis nula de que sigue una distribución normal para todos los predictores a excepción de para SepalWidth con un nivel de confianza del 95\%, aunque cabe mencionar que SepalWidth no se rechaza la hipótesis por muy poco, seguramente debido a esos valores extraños que vimos en la cola derecha del gráfico Q-Q.
