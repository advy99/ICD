\section{Análisis exploratorio de datos}

En este primer apartado realizaremos el análisis de los datos. Este análisis inicial nos servirá para visualizar como son los datos, si existen relaciones entre las distintas características que los conforman, así como extraer información de cada característica como pueden ser sus valores de interés, si cuenta con valores perdidos o anomalías así como más información. Además, también nos servirá para realizar hipótesis sobre como se comportarán los distintos predictores a la hora de generar un modelo, si algunos modelos no funcionarán debido a como están distribuidos los datos, entre otras.

\subsection{Conjunto de datos para regresión: baseball}

\subsubsection{Descripción del conjunto de datos}

Este conjunto de datos contiene información sobre distintas estadísticas de jugadores de béisbol, como el número de veces que batean, el número de partidos que juegan, los errores, entre otras estadísticas, así como su salario, que será el valor de salida que intentamos predecir.

Tras esta descripción del conjunto de datos, vamos a pasar a obtener distintas medidas de interés sobre los datos.


\subsubsection{Medidas de interés}

Lo primero a consultar de nuestro conjunto de datos es las dimensiones del mismo. Tras hacer uso del comando \texttt{dim}, vemos que el conjunto cuenta con 337 filas y 17 características (contando con la variable objetivo).

Tras esto pasamos a consultar el tipo de las características de cara a comprobar que se han leído de forma correcta. El comando \texttt{str} nos devolverá esta información, y vemos como todas son de tipo entero, a excepción del porcentaje de bateo y el porcentaje que un jugador llega a una base, que son de tipo numérico al contar con decimales.

Lo siguiente que comprobaremos, antes de consultar los propios valores de las variables será comprobar si existen valores perdidos. Para esto utilizaremos el comando \texttt{is.na} junto con el comando \texttt{any} para saber si se encuentra algún valor perdido. De forma gráfica también podemos utilizar el gráfico \texttt{missmap} del paquete Amelia:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/missmap_baseball}
	\caption{Mapa de valores perdidos en el conjunto de datos baseball.}
	\label{fig:missmap_baseball}
\end{figure}

Como vemos, este conjunto de datos no cuenta con valores perdidos, por lo que con esto pasamos a calcular las medidas de interés de cada predictor.


De cara a conocer el comportamiento de las características se han calculado los siguientes valores de interés para cada predictor:

\begin{itemize}
	\item Media
	\item Desviación estándar
	\item Mínimo
	\item Máximo
	\item Cuartiles
\end{itemize}


Estos valores los podemos consultar en el código en R adjunto, y aquí me comentaré la información más interesante que se ha obtenido.

Para empezar, observando los mínimos, máximos y cuartiles de las característica podemos ver que cuatro de los predictores, Free agency eligibility, Free agent, Arbitration eligibility y Arbitration, se han leído como valores numéricos del fichero de datos aunque se tratan de variables lógicas que solo toman dos valores, cero o uno.

Otro dato de interés con respecto a la variable de salida es que la media y la mediana son muy distintas, siendo la mediana casi la mitad del salario medio, sumado al gran valor de la desviación estándar del salario, podemos intuir que la mayoría de jugadores cobran un salario mucho menor que el salario máximo.

\subsubsection{Visualización gráfica del conjunto de datos}

Tras este primer vistazo a los datos y sus valores de interés, pasamos a representarlos de forma gráfica los datos.

Para empezar se ha realizado una gráfica general de los datos utilizando el comando \texttt{ggpairs}:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{baseball/vista_general_baseball}
	\caption{Vista general del conjunto de datos baseball.}
	\label{fig:vista_general_baseball}
\end{figure}

Aunque esta gráfica es muy difícil de leer ya que tenemos una gran cantidad de características, nos da una primera idea de que relaciones existen entre las variables así como su distribución.

Para ver más en detalle los valores que toma cada variable vamos ver un boxplot de cada una:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{baseball/boxplot_baseball}
	\caption{Boxplot de cada variable de baseball. \textbf{AVISO}: Mirar cada gráfica de forma independiente, la escala está libre.}
	\label{fig:boxplot_baseball}
\end{figure}

Se ha decidido poner la escala libre para evitar que una variable con valores muy amplios no nos deje ver los valores de las demás, por lo que hay que estudiar cada gráfica por separado y no realizar comparativas de estos gráficos sin tener en cuenta los ejes individuales de cada gráfica.

Con este gráfico podemos obtener bastante información sobre las variables. Para empezar, podemos observar que muchas de estas tienen valores anómalos según el método IQR, que aunque en principio en esta asignatura no trabajemos anomalías es algo que tenemos que tener en cuenta al usar estos predictores en nuestros modelos. También podemos ver que en ciertas variables como Batting average y On base percentage la mayoría de valores se concentran en un rango muy pequeño de valores, teniendo la mitad de valores entre el $0.24$ y el $0.3$ y entre $0.3$ y $0.36$ respectivamente, siendo ambas variables que expresan un porcentaje entre cero y uno. Otra variable a la que le ocurre lo mismo es a Stolen bases, donde la mitad de sus datos están entre el 0 y el 16, contando con bastantes valores anómalos.

Otra información a destacar de este gráfico son los cuatro boxplot de la esquina superior izquierda, Arbitration, Arbitration eligibility, Free agent eligibility y Free agent, que como vemos solo toman valores cero y uno, de ahí esas formas tan peculiares en los boxplots.


También se ha observado el gráfico de densidad de las características, de cara a observar la forma de la distribución en los datos:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/densidad_baseball}
	\caption{Gráfico de densidad de cada variable de baseball. \textbf{AVISO}: Mirar cada gráfica de forma independiente, la escala está libre.}
	\label{fig:densidad_baseball}
\end{figure}

Rápidamente podemos ver que tenemos una gran variedad de distribuciones. Como era de esperar, en las variables lógicas encontramos una distribución bimodal, aunque con este gráfico podemos ver que, a excepción de Free agency eligibility, en las otras tres variables predomina el valor cero.

Visualmente podemos ver que la que más se acerca a una distribución normal es Batting average, aunque tiene algunos valores en la cola izquierda que nos pueden hacer dudar si finalmente seguirá una normal.

Para ver esto más claramente, utilizaremos los gráficos Q-Q:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/qqplot_todos_baseball}
	\caption{Gráfico de normalidad Q-Q de cada variable de baseball.}
	\label{fig:qqplot_todos_baseball}
\end{figure}

En este gráfico podemos ver como, de nuevo, la más parecida a una normal es Batting average, aunque vemos como en las colas (en especial en la izquierda) observamos datos que no están sobre la linea.

De cara a comprobar estadisticamente si alguna de estas distribuciones es una distribución normal se ha aplicado el test de normalidad de Shapiro-Wilk, con el que no se ha podido rechazar la hipótesis nula para ninguna de las variables, luego no podemos concluir que sigan una distribución normal.

Finalmente, de cara a observar las relaciones entre las variables y si existe alguna correlación con la de salida se ha realizado un gráfico de la matriz de correlación:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{baseball/matriz_correlaciones_baseball}
	\caption{Matriz de correlaciones entre las variables de baseball.}
	\label{fig:matriz_correlaciones_baseball}
\end{figure}

De este gráfico podemos observar que existe un grupo de predictores altamente relacionados entre sí, Runs, Hits, Doubles y Runs batted in, por lo que se podría estudiar eliminar alguno de estos predictores para obtener un modelo más simple. También podemos observar que este grupo de predictores tiene una relación relativamente alta con la variable a predecir.

También existen otras variables que están correladas, como Batting average y On base percentaje, ya que tiene sentido que si un jugador batea más, tenga más probabilidad de llegar a una base, o entre On base percentage y Walks por el mismo motivo.


\subsubsection{Código R}

En esta sección está el código ejecutado en esta sección:

\begin{lstlisting}[language=R]
library(tidyverse)
library(readr)
library(Amelia)
library(ggplot2)
library(corrplot)
library(GGally)

#
# Funciones
#

mostrar_grafico_densidad <- function(datos, nombre_variable, save_plot = FALSE) {
	ggplot(data = datos, aes_string(x = nombre_variable, fill = "Class")) +
		geom_density(alpha = 0.5) +
		ggtitle(paste("Densidad de valores de ", nombre_variable, " por cada clase."))

	if (save_plot) {
		ggsave(paste("out/iris/densidad_iris_", nombre_variable, ".svg", sep = ""), device = svg, width = 1920, height = 1080, units = "px", dpi = 150)
	}
}

mostrar_boxplot <- function(datos, nombre_variable, save_plot = FALSE) {
	ggplot(data = datos, aes_string(x = nombre_variable, fill = "Class")) +
		geom_boxplot() +
		ggtitle(paste("Boxplot de ", nombre_variable, " por cada clase."))

	if (save_plot) {
		ggsave(paste("out/iris/boxplot_iris_", nombre_variable, ".svg", sep = ""), device = svg, width = 1920, height = 1080, units = "px", dpi = 150)
	}

}

mostrar_grafico_qq <- function(datos, nombre, save_plot = FALSE, directorio = "iris") {

	# para guardar la salida como svg, al no ser de ggplot
	# tenemos que hacerlo así ...
	if (save_plot) {
		svg(paste("out/", directorio, "/qqplot_", directorio,"_" , nombre, ".svg", sep = ""))
	}

	qqnorm(datos, main = paste("Normal Q-Q Plot: ", nombre))
	qqline(datos)

	if (save_plot) {
		dev.off()
	}
}


#
# Creación de directorios necesarios para la salida
#

directorios_necesarios <- list("out", "out/iris", "out/baseball")

lapply(directorios_necesarios, function(directorio) {if (!dir.exists(directorio)) dir.create(directorio) })


#
# Regresión
#


# leemos el fichero de datos
baseball <- read.csv("data/baseball/baseball.dat", comment.char = "@", header = FALSE)

# vamos a mirar las primeras filas
head(baseball)

# cambiamos los nombres de los atributos, no los ha leido bien el read.csv
names(baseball) <- c("Batting_average", "On-base_percentage", "Runs", "Hits",
					 "Doubles", "Triples", "HomeRuns", "Runs_batted_in", "Walks",
					 "Strike-Outs", "Stolen_bases", "Errors",
					 "Free_agency_eligibility", "Free_agent",
					 "Arbitration_eligibility", "Arbitration", "Salary")

head(baseball)

# miramos cuantas filas tenemos de datos
dim(baseball)

# miramos los tipos de los datos
str(baseball)

summary(baseball)

# el missmap nos modifica los valores por defecto de plot
# y luego el qqplot no se verá bien, así que los restauramos despues del missmap
par_default <- par(mar = c(0, 0, 0, 0))
# miramos si tenemos valores perdidos
svg("out/baseball/missmap_baseball.svg")
missmap(baseball)
dev.off()
par(par_default)

any(is.na(baseball))


# calculamos medidas de interes
# las calculamos sin tener en cuenta la clase de salida

# utilizamos una lista con las medidas de interes
medidas <- list(medias = mean,
				desviacion_estandar = sd,
				minimos = min,
				maximos = max)

# aplicamos cada medida a baseball por columnas
medidas_baseball <- lapply(medidas, function(funcion_medida) {
	apply(baseball, 2, funcion_medida)
} )
medidas_baseball

cuartiles_baseball <- apply(baseball, 2, quantile)
cuartiles_baseball


# graficamos los datos

# vistazo general
ggpairs(baseball, lower = list(combo = wrap("facethist", bins = 30))) + theme_minimal()
ggsave("out/baseball/vista_general_baseball.svg", device = svg, width = 1920, height = 1080, units = "px", dpi = 100)

#
## CUIDADO!!! LAS ESCALAS ESTAN LIBRES PORQUE NO SE HAN ESCALADO LOS DATOS
#
# He decidido no escalarlos de cada a ver los valores reales de los atributos, así
# que hay que mirar cada grafico por separado
ggplot(baseball %>% gather(), aes(x = value)) +
	geom_boxplot() +
	coord_flip() +
	facet_wrap(~key, scales = "free")
ggsave("out/baseball/boxplot_baseball.svg", device = svg, width = 1920, height = 1080, units = "px", dpi = 150)


ggplot(baseball %>% gather, aes(x = value)) +
	geom_density(alpha = 0.5, fill = "red") +
	facet_wrap(~key, scales = "free")
ggsave("out/baseball/densidad_baseball.svg", device = svg, width = 1920, height = 1080, units = "px", dpi = 150)



# tenemos 17 variables, hacemos primero 9 y luego las 8 restantes
par(mfrow=c(3,3))
lapply(colnames(baseball[1:9]), function(col_name) { mostrar_grafico_qq(baseball[,col_name], col_name, save_plot = TRUE, directorio = "baseball") } )
lapply(colnames(baseball[10:17]), function(col_name) { mostrar_grafico_qq(baseball[,col_name], col_name, save_plot = TRUE, directorio = "baseball") } )
par(mfrow=c(1,1))


# test de normalidad sobre las características
resultados_test_normalidad <- apply(baseball, 2, shapiro.test)

# si su p-value es menor que 0.05 rechazamos la hipotesis de que sigue una distribución normal
sigue_distribucion_normal <- lapply(resultados_test_normalidad, function(x) x$p.value > 0.05)

# los que no rechacen supondremos que siguen una normal
sigue_distribucion_normal

# como podemos ver en los p-value, rechazamos la hipotesis nula de que los datos siguen
# una distribución normal a excepción de la segunda característica, SepalWidth ,por muy poco


matriz_correlaciones_baseball <- cor(baseball)
matriz_correlaciones_baseball


svg("out/baseball/matriz_correlaciones_baseball.svg")
corrplot(matriz_correlaciones_baseball, method = "ellipse")
dev.off()
\end{lstlisting}

\subsection{Conjunto de datos para clasificación: iris}

\subsubsection{Descripción del conjunto de datos}

Este conjunto contiene información sobre las medidas del pétalo y sépalo de tres tipos distintos de la flor Iris. Nos proporciona tanto la longitud como el ancho del pétalo y sépalo de estas tres clases:

\begin{itemize}
	\item Versicolor
	\item Virginica
	\item Setosa
\end{itemize}

\subsubsection{Medidas de interés}

Lo primero a consultar de nuestro conjunto de datos es las dimensiones del mismo. Tras hacer uso del comando \texttt{dim}, vemos que el conjunto cuenta con 150 filas y 5 características (contando con la clase a predecir).

Tras esto pasamos a consultar el tipo de las características de cara a comprobar que se han leído de forma correcta. El comando \texttt{str} nos devolverá esta información, y vemos como todas a excepción de la clase son de tipo numérico al contar con decimales. La clase a la que pertenecen le ha asignado el tipo carácter, sin embargo lo vamos a transformar a factor con el comando \texttt{as.factor} ya que se tratan de tres niveles sin orden distintos, las tres clases a clasificar.

Al igual que con el conjunto de regresión, antes de consultar los propios valores de las variables será comprobar si existen valores perdidos. Para esto utilizaremos el comando \texttt{is.na} junto con el comando \texttt{any} para saber si se encuentra algún valor perdido. De forma gráfica también podemos utilizar el gráfico \texttt{missmap} del paquete Amelia:


\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{iris/missmap_iris}
	\caption{Mapa de valores perdidos en el conjunto de datos iris.}
	\label{fig:missmap_iris}
\end{figure}

Como podemos ver, en este conjunto de datos tampoco existen valores perdidos.

Como en regresión, se han calculado los siguientes valores de interés para cada predictor (a excepción de la clase ya que no es de tipo numérico):

\begin{itemize}
	\item Media
	\item Desviación estándar
	\item Mínimo
	\item Máximo
	\item Cuartiles
\end{itemize}


Estos valores los podemos consultar en el código en R adjunto, y aquí me comentaré la información más interesante que se ha obtenido.

Como podemos ver con los máximos y mínimos, todos los valores están en un rango similar de valores. Con estos valores vemos que son relativamente normales, en los que se asemeja la media con la mediana, aunque es cierto que podemos ver que para la variable PetalLength la desviación típica es más alta que para las demás.

\subsubsection{Visualización gráfica del conjunto de datos}

Para comenzar, también realizaremos una gráfica más general para ver de una manera más rápida el conjunto de datos iris:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/vista_general_iris}
	\caption{Vista general del conjunto de datos iris.}
	\label{fig:vista_general_iris}
\end{figure}


Con este gráfico podemos comenzar a obtener información bastante interesante, aun así voy a utilizar los gráficos completos para mostrar una mejor visualización, comenzando por el número de observaciones para cada clase, ya que esto es muy importante en un problema de clasificación:

\begin{figure}[H]
	\centering
	\includesvg[width = 400pt]{iris/recuento_clases_iris}
	\caption{Número de observaciones de cada clase para el conjunto de datos iris.}
	\label{fig:recuento_clases_iris}
\end{figure}

Como vemos, en este caso las clases están balanceadas, es decir, tenemos el mismo número de observaciones para cada clase, lo que ayudará a evitar que se sobreaprendan algunas clases, o que no tengamos suficientes muestras como para aprender una clase.

En esta sección, debido que el problema se basa en ser capaces de distinguir entre las clases en los gráficos distinguiremos las clases del problema. Vamos a empezar con los boxplot para ver como están distribuidos los valores de cada predictor:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_SepalWidth}
	\caption{Boxplot para el predictor SepalWidth de iris.}
	\label{fig:boxplot_iris_SepalWidth}
\end{figure}

Con respecto a SepalWidth podemos encontrar dos valores anómalos utilizando el método IQR en la clase Virginica, además de un gran solape entre las tres clases, por lo que podemos intuir que no será un buen predictor.


\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_SepalLength}
	\caption{Boxplot para el predictor SepalLength de iris.}
	\label{fig:boxplot_iris_SepalLength}
\end{figure}

Al igual que con la característica anterior, con SepalLength también existe un alto solapamiento, aunque algo mejor, y volvemos a encontrar una anomalía en la clase Virginica.


\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_PetalWidth}
	\caption{Boxplot para el predictor PetalWidth de iris.}
	\label{fig:boxplot_iris_PetalWidth}
\end{figure}

En este caso, utilizando PetalWidth, en la clase Setosa no existe ningún solapamiento, estando todos los valores concentrados entre cero y un medio, aunque si existe cierto solapamiento aunque no muy alto entre las otras dos variables, con lo que podemos intuir que esta variable nos dará bastante información a la hora de predecir la clase.

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/boxplot_iris_PetalLength}
	\caption{Boxplot para el predictor PetalLength de iris.}
	\label{fig:boxplot_iris_PetalLength}
\end{figure}

Al igual que PetalWidth, PetalLength también nos servierá para predecir la clase Setosa, estando sus valores muy concentrados en valores entre uno y dos.

Y con esto, de cara a comprobar las distribuciones que sigue cada predictor y comprobar las hipótesis realizadas con los boxplots, pasamos a los gráficos de densidad:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_SepalWidth}
	\caption{Gráfico de densidad para el predictor SepalWidth de iris.}
	\label{fig:densidad_iris_SepalWidth}
\end{figure}

Con este primer gráfico de densidad, del predictor SepalWidth, podemos ver que este predictor no será capaz de realizar una buena distinción entre las clases, ya que se solapan todas en gran medida, aunque es cierto que se pueden observar ciertas diferencias con la clase Setosa.

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_SepalLength}
	\caption{Gráfico de densidad para el predictor SepalLength de iris.}
	\label{fig:densidad_iris_SepalLength}
\end{figure}

La variable SepalWidth es capaz de distinguir de mejor forma las clases, en especial Setosa, aunque sigue existiendo un gran solape entre Versicolor y Virginica.

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_PetalWidth}
	\caption{Gráfico de densidad para el predictor PetalWidth de iris.}
	\label{fig:densidad_iris_PetalWidth}
\end{figure}

En este caso podemos ver como con PetalWidth podemos hacer una distinción perfecta entre Setosa y el resto de clases, además de reducir en gran cantidad el solape entre Versicolor y Virginica.

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/densidad_iris_PetalLength}
	\caption{Gráfico de densidad para el predictor PetalLength de iris.}
	\label{fig:densidad_iris_PetalLength}
\end{figure}

Por último, con PetalLength también se puede hacer una distinción perfecta entre Setosa y el resto de clases, aunque sigue existiendo un solape entre Versicolor y Virginica.

Con estos cuatro gráficos vemos que podemos esperar distinguir las observaciones de Setosa con el resto sin ningún problema gracias a las medidas del pétalo, haciendo que los errores se encuentren en las clases Versicolor y Virginica, aunque este error no será muy alto ya que también gracias a las medidas del pétalo el solape es menor, y posiblemente con toda la información en conjunto se consiga distinguir todavía mejor ese solape que vemos ahora.


Tras estos gráficos de densidad, pasamos a observar si los predictores siguen una distribución normal, para esto se ha usado de nuevo el gráfico Q-Q, además del test estadístico de Shapiro-Wilk:

\begin{figure}[H]
	\centering
	\includesvg[width = 500pt]{iris/qqplot_iris}
	\caption{Gráfico de normalidad Q-Q de cada variable de iris.}
	\label{fig:qqplot_iris}
\end{figure}


Podemos ver que gráficamente la que más se acerca a una distribución normal es SepalWidth, aunque los valores en la cola derecha nos dan a intuir que no será así.

Tras lanzar el test de normalidad de Shapiro-Wilk rechazamos la hipótesis nula de que sigue una distribución normal para todos los predictores a excepción de para SepalWidth con un nivel de confianza del 95\%, aunque cabe mencionar que SepalWidth no se rechaza la hipótesis por muy poco, seguramente debido a esos valores extraños que vimos en la cola derecha del gráfico Q-Q.


\subsubsection{Código R}

En esta sección está el código ejecutado en esta sección:

\begin{lstlisting}[language=R]
library(tidyverse)
library(readr)
library(Amelia)
library(ggplot2)
library(corrplot)
library(GGally)


#
# Funciones
#

mostrar_grafico_densidad <- function(datos, nombre_variable, save_plot = FALSE) {
	ggplot(data = datos, aes_string(x = nombre_variable, fill = "Class")) +
		geom_density(alpha = 0.5) +
		ggtitle(paste("Densidad de valores de ", nombre_variable, " por cada clase."))

	if (save_plot) {
		ggsave(paste("out/iris/densidad_iris_", nombre_variable, ".svg", sep = ""), device = svg, width = 1920, height = 1080, units = "px", dpi = 150)
	}
}

mostrar_boxplot <- function(datos, nombre_variable, save_plot = FALSE) {
	ggplot(data = datos, aes_string(x = nombre_variable, fill = "Class")) +
		geom_boxplot() +
		ggtitle(paste("Boxplot de ", nombre_variable, " por cada clase."))

	if (save_plot) {
		ggsave(paste("out/iris/boxplot_iris_", nombre_variable, ".svg", sep = ""), device = svg, width = 1920, height = 1080, units = "px", dpi = 150)
	}

}

mostrar_grafico_qq <- function(datos, nombre, save_plot = FALSE, directorio = "iris") {

	# para guardar la salida como svg, al no ser de ggplot
	# tenemos que hacerlo así ...
	if (save_plot) {
		svg(paste("out/", directorio, "/qqplot_", directorio,"_" , nombre, ".svg", sep = ""))
	}

	qqnorm(datos, main = paste("Normal Q-Q Plot: ", nombre))
	qqline(datos)

	if (save_plot) {
		dev.off()
	}
}


#
# Creación de directorios necesarios para la salida
#

directorios_necesarios <- list("out", "out/iris", "out/baseball")

lapply(directorios_necesarios, function(directorio) {if (!dir.exists(directorio)) dir.create(directorio) })



#
# Clasificación
#


# leemos el fichero de datos
iris <- read.csv("data/iris/iris.dat", comment.char = "@", header = FALSE)

# vamos a mirar las primeras filas
head(iris)

# cambiamos los nombres de los atributos, no los ha leido bien el read.csv
names(iris) <- c("SepalLength", "SepalWidth", "PetalLength", "PetalWidth", "Class")

head(iris)

# miramos cuantas filas tenemos de datos
dim(iris)

# miramos los tipos de los datos
str(iris)

# pasamos a factor la clase del problema
iris$Class <- as.factor(iris$Class)
summary(iris)

# el missmap nos modifica los valores por defecto de plot
# y luego el qqplot no se verá bien, así que los restauramos despues del missmap
par_default <- par(mar = c(0, 0, 0, 0))
# miramos si tenemos valores perdidos
# abrimos un dispositivo de salida en formato svg
svg("out/iris/missmap_iris.svg")
missmap(iris)
# lo cerramos al terminar de dibujar
dev.off()
par(par_default)

any(is.na(iris))


# calculamos medidas de interes
# las calculamos sin tener en cuenta la clase de salida

# utilizamos una lista con las medidas de interes
medidas <- list(medias = mean,
				desviacion_estandar = sd,
				minimos = min,
				maximos = max)

# aplicamos cada medida a iris por columnas
medidas_iris <- lapply(medidas, function(funcion_medida) {
									apply(iris[,-5], 2, funcion_medida)
								} )
medidas_iris

cuartiles_iris <- apply(iris[,-5], 2, quantile)
cuartiles_iris

# graficamos los datos

# vistazo general
ggpairs(iris, aes(colour = Class),  lower = list(combo = wrap("facethist", bins = 20))) + theme_minimal()
ggsave("out/iris/vista_general_iris.svg", device = svg, width = 1920, height = 1080, units = "px", dpi = 150)


mostrar_grafico_densidad(iris, "SepalLength", save_plot = TRUE)
mostrar_grafico_densidad(iris, "SepalWidth", save_plot = TRUE)
mostrar_grafico_densidad(iris, "PetalLength", save_plot = TRUE)
mostrar_grafico_densidad(iris, "PetalWidth", save_plot = TRUE)


mostrar_boxplot(iris, "SepalLength", save_plot = TRUE)
mostrar_boxplot(iris, "SepalWidth", save_plot = TRUE)
mostrar_boxplot(iris, "PetalLength", save_plot = TRUE)
mostrar_boxplot(iris, "PetalWidth", save_plot = TRUE)


ggplot(iris, aes(x = Class, fill = Class)) +
	geom_bar() +
	guides(fill = "none") +
	xlab("Número de observaciones") +
	ylab("Clases") +
	ggtitle("Recuento de observaciones para cada clase")
ggsave("out/iris/recuento_clases_iris.svg", device = svg, width = 1920, height = 1080, units = "px", dpi = 150)

# miramos si cada característica sigue una distribución normal
par(mfrow=c(2,2))
lapply(colnames(iris[,-5]), function(col_name) { mostrar_grafico_qq(iris[,col_name], col_name, save_plot = TRUE) } )
par(mfrow=c(1,1))



# test de normalidad sobre las características, separado por cada clase
apply(iris %>% select_if(is.numeric), 2, shapiro.test)


# como podemos ver en los p-value, rechazamos la hipotesis nula de que los datos siguen
# una distribución normal a excepción de la segunda característica, SepalWidth ,por muy poco


matriz_correlaciones_iris <- cor(iris[, -5])
matriz_correlaciones_iris

svg("out/iris/matriz_correlaciones_iris.svg")
corrplot(matriz_correlaciones_iris, method = "ellipse")
dev.off()
\end{lstlisting}
